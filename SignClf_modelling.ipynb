{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1Xw-DPRb3YmEY9MWh6FMdwmfP_7sZHbBT","authorship_tag":"ABX9TyOpJvH+UTL4Qm81ANZPoZSM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DTviVnr3sJCZ"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","\n","import os\n","import zipfile\n","import datetime\n","import shutil\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout"]},{"cell_type":"code","source":["local_zip = '/content/drive/MyDrive/DL_dataset2/data.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall()"],"metadata":{"id":"qRCL4sQytAW6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(os.listdir('/content/train/Signed')))\n","print(len(os.listdir('/content/train/Unsigned')))\n","print(len(os.listdir('/content/val/Signed')))\n","print(len(os.listdir('/content/val/Unsigned')))\n","print(len(os.listdir('/content/train/sign')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgD_WAjawINj","executionInfo":{"status":"ok","timestamp":1662181943235,"user_tz":-330,"elapsed":1087,"user":{"displayName":"20MSC52 SUNDARESAN CG","userId":"13279548266259704776"}},"outputId":"ba6fe8ab-ba07-4ed5-deeb-8648928db9c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["23489\n","23489\n","1000\n","1000\n","25000\n"]}]},{"cell_type":"code","source":["dir_1 = '/content/train/Signed'\n","dir_2 = '/content/train/sign'\n","\n","dir1_lst = os.listdir(dir_1)\n","dir1_lst.sort()\n","\n","for img in dir1_lst[:25000]:\n","  shutil.move(os.path.join(dir_1, img), os.path.join(dir_2, img))\n","\n","dir_3 = '/content/val/Sign'\n","\n","for img in dir1_lst[25000:]:\n","  shutil.move(os.path.join(dir_1, img), os.path.join(dir_3, img))"],"metadata":{"id":"a1VR9P0EtUui"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_gen = ImageDataGenerator(rescale=1/255)\n","validation_data_gen = ImageDataGenerator(rescale=1/255)\n","\n","train_gen = train_data_gen.flow_from_directory(\n","    '/content/train',\n","    target_size = (256,256),\n","    batch_size = 32,\n","    class_mode = 'binary'\n",")\n","\n","val_gen = train_data_gen.flow_from_directory(\n","    '/content/val',\n","    target_size = (256,256),\n","    batch_size = 16,\n","    class_mode = 'binary'\n",")"],"metadata":{"id":"sZbS0EVetgR9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662822630012,"user_tz":-330,"elapsed":1860,"user":{"displayName":"20MSC52 SUNDARESAN CG","userId":"13279548266259704776"}},"outputId":"124e175f-091d-4b7b-de3e-789581d53fb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 46978 images belonging to 2 classes.\n","Found 2000 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["train_data_gen = ImageDataGenerator(rescale=1/255)\n","validation_data_gen = ImageDataGenerator(rescale=1/255)\n","\n","train_gen = train_data_gen.flow_from_directory(\n","    '/content/train',\n","    target_size = (256,256),\n","    batch_size = 32,\n","    class_mode = 'binary'\n",")\n","\n","val_gen = train_data_gen.flow_from_directory(\n","    '/content/val',\n","    target_size = (256,256),\n","    batch_size = 16,\n","    class_mode = 'binary'\n",")"],"metadata":{"id":"NeajAIVXyhtc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(layers.Conv2D(input_shape=(256, 256, 3), filters=64,kernel_size=(3,3), padding=\"same\",activation='relu'))\n","model.add(layers.Conv2D(filters=32,kernel_size=(3,3), padding=\"same\",activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n"],"metadata":{"id":"I1PZvteWyMjH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(1,activation='sigmoid'))"],"metadata":{"id":"mdirLjt9ym1E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"DtI9hQl_yo4f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662793669320,"user_tz":-330,"elapsed":67,"user":{"displayName":"20MSC52 SUNDARESAN CG","userId":"13279548266259704776"}},"outputId":"90d654b0-55c0-427c-ca36-ffabb3a3f348"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 256, 256, 64)      1792      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 256, 256, 32)      18464     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 128, 128, 32)     0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 126, 126, 128)     36992     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 63, 63, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 61, 61, 256)       295168    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 30, 30, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 28, 28, 128)       295040    \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 14, 14, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 12, 12, 64)        73792     \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 4, 4, 64)          36928     \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                16448     \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 774,689\n","Trainable params: 774,689\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.optimizers import Adam\n","model.compile(loss = 'binary_crossentropy',\n","             optimizer = 'Adam',\n","             metrics = ['accuracy'])"],"metadata":{"id":"f275vBfdyvuA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["early_stopping=tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=5)"],"metadata":{"id":"y3GGH9jrywci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_fit = model.fit(train_gen,\n","                     epochs = 20,\n","                     verbose = 1,\n","                      steps_per_epoch=100,\n","                     validation_data = val_gen,\n","                      callbacks = early_stopping)\n"],"metadata":{"id":"4NzuLmo8y1KK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662794068173,"user_tz":-330,"elapsed":390816,"user":{"displayName":"20MSC52 SUNDARESAN CG","userId":"13279548266259704776"}},"outputId":"48f48f94-1902-4e3f-e124-f7138d947581"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","100/100 [==============================] - 41s 256ms/step - loss: 0.5093 - accuracy: 0.7688 - val_loss: 0.6020 - val_accuracy: 0.7565\n","Epoch 2/20\n","100/100 [==============================] - 25s 249ms/step - loss: 0.4377 - accuracy: 0.8238 - val_loss: 0.5498 - val_accuracy: 0.7605\n","Epoch 3/20\n","100/100 [==============================] - 25s 252ms/step - loss: 0.3887 - accuracy: 0.8450 - val_loss: 0.5881 - val_accuracy: 0.7410\n","Epoch 4/20\n","100/100 [==============================] - 26s 254ms/step - loss: 0.3902 - accuracy: 0.8350 - val_loss: 0.4320 - val_accuracy: 0.8230\n","Epoch 5/20\n","100/100 [==============================] - 26s 258ms/step - loss: 0.3329 - accuracy: 0.8722 - val_loss: 0.4722 - val_accuracy: 0.7990\n","Epoch 6/20\n","100/100 [==============================] - 26s 259ms/step - loss: 0.3101 - accuracy: 0.8844 - val_loss: 0.3175 - val_accuracy: 0.8850\n","Epoch 7/20\n","100/100 [==============================] - 26s 259ms/step - loss: 0.3131 - accuracy: 0.8806 - val_loss: 0.4437 - val_accuracy: 0.8355\n","Epoch 8/20\n","100/100 [==============================] - 26s 256ms/step - loss: 0.2955 - accuracy: 0.8872 - val_loss: 0.4258 - val_accuracy: 0.8225\n","Epoch 9/20\n","100/100 [==============================] - 26s 257ms/step - loss: 0.2722 - accuracy: 0.8944 - val_loss: 0.4461 - val_accuracy: 0.8420\n","Epoch 10/20\n","100/100 [==============================] - 26s 258ms/step - loss: 0.2738 - accuracy: 0.9047 - val_loss: 0.5177 - val_accuracy: 0.7875\n","Epoch 11/20\n","100/100 [==============================] - 26s 256ms/step - loss: 0.2558 - accuracy: 0.9069 - val_loss: 0.4661 - val_accuracy: 0.8050\n"]}]},{"cell_type":"code","source":["model.save('model1.h5')"],"metadata":{"id":"VsevZRVnDYUU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["local_zip = '/content/drive/MyDrive/DL_dataset2/inference.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall()"],"metadata":{"id":"HiuXrRlLXfvF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inf_model = models.load_model('/content/model1.h5')"],"metadata":{"id":"ixQ2Pm6BX6z-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_gen = ImageDataGenerator(rescale=1/255)\n","validation_data_gen = ImageDataGenerator(rescale=1/255)\n","\n","infer_gen = train_data_gen.flow_from_directory(\n","    '/content/infer',\n","    target_size = (256,256),\n","    batch_size = 32,\n","    class_mode = 'binary'\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QespLh3FYo7V","executionInfo":{"status":"ok","timestamp":1662796385939,"user_tz":-330,"elapsed":349,"user":{"displayName":"20MSC52 SUNDARESAN CG","userId":"13279548266259704776"}},"outputId":"9aa4713b-3ea7-4483-e125-69f0b935f1b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 6000 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["score = inf_model.evaluate(infer_gen, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_J7ddlCY1h-","executionInfo":{"status":"ok","timestamp":1662796441827,"user_tz":-330,"elapsed":15185,"user":{"displayName":"20MSC52 SUNDARESAN CG","userId":"13279548266259704776"}},"outputId":"385df33a-9765-4281-beff-c566e2350651"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["188/188 [==============================] - 15s 78ms/step - loss: 0.1636 - accuracy: 0.9482\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from os import listdir\n","\n","dir_sign = '/content/train/Signed'\n","dir_sign_list = listdir(dir_sign)\n","dir_sign_list.sort()\n","\n","wpx = 0\n","for img in dir_sign_list:\n","  img = cv2.imread(os.path.join(dir_sign,img))\n","  wcount = (np.count_nonzero(img)/img.size)*100\n","  wpx = wpx + count\n","\n","avg_wpx = wpx/len(dir_sign_list)\n","print(avg_wpx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gs83ljUZIBk","executionInfo":{"status":"ok","timestamp":1662798627388,"user_tz":-330,"elapsed":34734,"user":{"displayName":"20MSC52 SUNDARESAN CG","userId":"13279548266259704776"}},"outputId":"1c7d1f6c-f157-4479-fb79-8311e2343c6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["59.20936771798022\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from os import listdir\n","\n","dir_unsign = '/content/train/Unsigned'\n","dir_unsign_list = listdir(dir_unsign)\n","dir_unsign_list.sort()\n","\n","bpx = 0\n","for img in dir_unsign_list:\n","  img = cv2.imread(os.path.join(dir_unsign,img))\n","  bcount = (np.count_nonzero(img)/img.size)*100\n","  bpx = bpx + count\n","\n","avg_bpx = bpx/len(dir_unsign_list)\n","print(avg_bpx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FI_i-kbohYsd","outputId":"de1ee232-d240-4811-8d99-62520337ba0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["49.53740820015236\n"]}]},{"cell_type":"code","source":["dir_sign = '/content/train/Signed'\n","dir_sign_list = os.listdir(dir_sign)\n","dir_sign_list.sort()\n","crct = 0\n","incrt = 0\n","for image_nm in dir_sign_list:\n","  img = cv2.imread(os.path.join(dir_sign,image_nm))\n","  wcount = (np.count_nonzero(img)/img.size)*100\n","  if wcount >= 59:  crct = crct +1\n","  else: incrt = incrt +1\n","\n","print(\"Correctly classified:\",crct,\"\\tIncorrectly classified:\",incrt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L2c6HUDIjTh3","executionInfo":{"status":"ok","timestamp":1662799498817,"user_tz":-330,"elapsed":32590,"user":{"displayName":"20MSC52 SUNDARESAN CG","userId":"13279548266259704776"}},"outputId":"a78693a8-3fab-4568-c11f-d0780c6e2e27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Correctly classified: 13923 \tIncorrectly classified: 9566\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"50A-msNRjTx3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XKsvXsBhiDTe","executionInfo":{"status":"ok","timestamp":1662799899495,"user_tz":-330,"elapsed":9498,"user":{"displayName":"20MSC52 SUNDARESAN CG","userId":"13279548266259704776"}},"outputId":"dd017ca5-2500-46d6-cc9b-60bd6955ef4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.8.11-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.5 MB)\n","\u001b[K     |████████████████████████████████| 31.5 MB 824 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (22.1.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.6.0.66)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.2.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.11->mediapipe) (1.15.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n","Installing collected packages: mediapipe\n","Successfully installed mediapipe-0.8.11\n"]}]},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","import math\n","import numpy as np\n","\n","DESIRED_HEIGHT = 480\n","DESIRED_WIDTH = 480\n","def resize_and_show(image):\n","  h, w = image.shape[:2]\n","  if h < w:\n","    img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n","  else:\n","    img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n","  cv2_imshow(img)\n","\n","# Read images with OpenCV.\n","images = {name: cv2.imread(name) for name in uploaded.keys()}\n","# Preview the images.\n","for name, image in images.items():\n","  print(name)   \n","  resize_and_show(image)"],"metadata":{"id":"mYEW9nfE3GBA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import mediapipe as mp\n","mp_pose = mp.solutions.pose\n","mp_drawing = mp.solutions.drawing_utils \n","mp_drawing_styles = mp.solutions.drawing_styles\n","\n","with mp_pose.Pose(\n","    static_image_mode=True, min_detection_confidence=0.5, model_complexity=2) as pose:\n","  for name, image in images.items():\n","    # Convert the BGR image to RGB and process it with MediaPipe Pose.\n","    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    \n","    # Print nose landmark.\n","    image_hight, image_width, _ = image.shape\n","    if not results.pose_landmarks:\n","      continue\n","    print(\n","      f'Wrist coordinates: ('\n","      f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST].x * image_width}, '\n","      f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST].y * image_hight})'\n","    )\n","\n","    # Draw pose landmarks.\n","    print(f'Pose landmarks of {name}:')\n","    annotated_image = image.copy()\n","    mp_drawing.draw_landmarks(\n","        annotated_image,\n","        results.pose_landmarks,\n","        mp_pose.POSE_CONNECTIONS,\n","        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n","    resize_and_show(annotated_image)"],"metadata":{"id":"WXRNp6NH3QZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run MediaPipe Pose and draw pose landmarks.\n","with mp_pose.Pose(\n","    static_image_mode=True, min_detection_confidence=0.5, model_complexity=2) as pose:\n","  for name, image in images.items():\n","    # Convert the BGR image to RGB and process it with MediaPipe Pose.\n","    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    \n","    # Print nose landmark.\n","    image_hight, image_width, _ = image.shape\n","    if not results.pose_landmarks:\n","      continue\n","    print(\n","      f'Wrist coordinates: ('\n","      f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x * image_width}, '\n","      f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y * image_hight})'\n","    )\n","\n","    # Draw pose landmarks.\n","    print(f'Pose landmarks of {name}:')\n","    annotated_image = image.copy()\n","    mp_drawing.draw_landmarks(\n","        annotated_image,\n","        results.pose_landmarks,\n","        mp_pose.POSE_CONNECTIONS,\n","        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n","    resize_and_show(annotated_image)"],"metadata":{"id":"yJQmFB9dmPTj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run MediaPipe Pose and plot 3d pose world landmarks.\n","with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5, model_complexity=2) as pose:\n","  for name, image in images.items():\n","    results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","\n","    #3D coordinates of nose in meters with the origin at the center between hips.\n","    print('Nose world landmark:')\n","    print(results.pose_world_landmarks.landmark[mp_pose.PoseLandmark.NOSE])\n","    \n","    # Plot pose world landmarks.\n","    mp_drawing.plot_landmarks(\n","        results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)"],"metadata":{"id":"snNdFHVx2wl5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"f57yZdsWle1d"}}]}